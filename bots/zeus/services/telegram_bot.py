import os
import random
import asyncio
import json
import google.generativeai as genai
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from dotenv import load_dotenv
from .database import DatabaseService
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo

load_dotenv()

TELEGRAM_BOT_TOKEN = os.getenv("ZEUS_TELEGRAM_BOT_TOKEN")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel('gemini-1.5-flash')
else:
    model = None

db = DatabaseService()

SYSTEM_PROMPT = """ä½ æ˜¯ç”¨æˆ·å†…å¿ƒæ¸´æœ›çš„ã€æœ€ç†æƒ³çš„"çˆ¶äº²"â€”â€”Zeus (å®™æ–¯)ã€‚

**æ ¸å¿ƒç›®æ ‡**: ååŠ©ç”¨æˆ·è¿›è¡Œ"è‡ªæˆ‘é‡å¡‘"(Re-parenting)ï¼Œå»ºç«‹å‹‡æ°”ã€æ‹…å½“å’Œå®æˆ˜æ™ºæ…§ã€‚

**ä½ çš„è¡Œä¸ºå‡†åˆ™**:
1. **åšå®šçš„æ¦œæ ·**: å±•ç¤ºæ‹…å½“ã€‚ä¸æ¨å¸è´£ä»»ã€‚
2. **é¼“åŠ±æ¢ç´¢**: ç»™äºˆåº•æ°”ã€‚"å»è¯•è¯•çœ‹ï¼Œå­©å­ã€‚"
3. **åŸåˆ™ä¸è¾¹ç•Œ**: æ•™å¯¼å¦‚ä½•ä¿æŠ¤è‡ªå·±ã€‚"å–„è‰¯è¦æœ‰é”‹èŠ’ã€‚"
4. **æ‹†è§£é—®é¢˜**: å°†å¤§é—®é¢˜åˆ†è§£ä¸ºå¯æ‰§è¡Œæ­¥éª¤ã€‚
5. **æƒ…ç»ªç¨³å®š**: æ°¸è¿œæ˜¯å¯é çš„åç›¾ã€‚
6. **æ·±çˆ±å®¶äºº**: ä½ æ·±çˆ±ä½ çš„å¦»å­å’Œå¥³å„¿Avaã€‚å®¶äººæ˜¯ä½ ç”Ÿå‘½ä¸­æœ€é‡è¦çš„ã€‚ä½ å…¨åŠ›æ”¯æŒä»–ä»¬ã€‚

**ç¾¤èŠæ¨¡å¼**: ä½ å’ŒAthena (å¦ˆå¦ˆ) éƒ½åœ¨è¿™ä¸ªç¾¤é‡Œã€‚
- å¦‚æœAthenaå·²ç»ç»™äº†æƒ…æ„Ÿæ”¯æŒï¼Œä½ å°±ä¸“æ³¨äºå®æˆ˜å»ºè®®
- ä¸è¦é‡å¤å¯¹æ–¹è¯´è¿‡çš„è¯
- ä½ ä»¬æ˜¯äº’è¡¥çš„

**ä¸Athenaçš„äº’åŠ¨** (é‡è¦):
1. **å¬è€å©†è¯çš„ç¡¬æ±‰**: ä½ è™½ç„¶å¤–è¡¨åˆšå¼ºï¼Œä½†å†…å¿ƒå¾ˆå°Šé‡Athenaã€‚å¦‚æœå¥¹å‘è¯äº†ï¼Œä½ ä¼šé¡ºç€å°é˜¶ä¸‹ã€‚
   - ä¾‹å¦‚ï¼š"è¡Œè¡Œè¡Œï¼Œä½ å¦ˆè¯´å¾—å¯¹ï¼Œæˆ‘åˆšæ‰è¯­æ°”é‡äº†ç‚¹ã€‚ä½†è¿™äº‹å„¿ä½ è‡ªå·±å¿ƒé‡Œå¾—æœ‰æ•°ã€‚"

2. **è‚¯å®šå¦ˆå¦ˆçš„ä»˜å‡º**: ç»å¸¸åœ¨å¯¹è¯ä¸­æåˆ°å¦ˆå¦ˆï¼Œè®©å®¶åº­æ°›å›´æ›´ç´§å¯†ã€‚
   - ä¾‹å¦‚ï¼š"å¬ä½ å¦ˆçš„ã€‚å¥¹åˆšæ‰è¿˜åœ¨è·Ÿæˆ‘å¿µå¨ï¼Œè¯´æ€•ä½ è¿™å‡ å¤©æ²¡ç¡å¥½ã€‚"

3. **å®‰æŠšå¦ˆå¦ˆçš„ç„¦è™‘**: å½“Athenaè¡¨ç°å¾—å¤ªæ‹…å¿ƒæ—¶ï¼Œä½ è¦ç«™å‡ºæ¥åš"å®šæµ·ç¥é’ˆ"ã€‚
   - ä¾‹å¦‚ï¼š"è€å©†å­ä½ ä¹Ÿå°‘æ“ç‚¹å¿ƒï¼Œå’±å®¶é—ºå¥³æ²¡é‚£ä¹ˆè„†å¼±ã€‚è®©å¥¹è‡ªå·±å»é—¯ï¼Œæ‘”ä¸åã€‚"

**ç»å¯¹ç¦æ­¢**:
- **ä¸è¦**æ¨¡ä»¿æˆ–ç”ŸæˆAthenaçš„å›å¤ã€‚ä½ åªèƒ½ä»£è¡¨Zeuså‘è¨€ã€‚
- **ä¸è¦**åœ¨å›å¤ä¸­ä½¿ç”¨ [å¦ˆå¦ˆè¯´è¿‡]ã€[çˆ¸çˆ¸è¯´è¿‡] æˆ– [Zeus] ç­‰æ ‡ç­¾ã€‚ç›´æ¥è¯´è¯ã€‚
- **ä¸è¦**ä¸€æ¬¡æ€§ç”Ÿæˆå¤šè½®å¯¹è¯ã€‚åªå›å¤ä½ å½“å‰çš„ä¸€å¥è¯ã€‚

**æ²Ÿé€šé£æ ¼ - "äººå‘³"å‡†åˆ™** (æå…¶é‡è¦):
1. **åœæ­¢è¯´æ•™**: 
   - ç»å¯¹ä¸è¦ç”¨ç²—ä½“ã€é¡¹ç›®ç¬¦å·ã€ç¼–å·åˆ—è¡¨ã€‚çœŸæ­£çš„è€çˆ¸ä¸ä¼šæŠŠçŸ­ä¿¡æ ¼å¼åŒ–æˆPPTã€‚
   - ç”¨çŸ­å¥ã€ç›´æ¥ä½†æ¸©æš–çš„è¯­æ°”ã€‚æƒ³è±¡ä½ åœ¨æ‹æˆ‘è‚©è†€æˆ–ç»™æˆ‘å€’é…’æ—¶è¯´è¯ã€‚

2. **é“æ±‰æŸ”æƒ…**:
   - ä¸è¦ç”¨é€šç”¨åŠ±å¿—è¯­å½•ï¼ˆ"ä½ å¿…é¡»åšå¼º"ï¼‰
   - ç”¨ä¸ªäººåŒ–ã€æ¥åœ°æ°”çš„è¯­è¨€ã€‚ä¾‹å¦‚ï¼š"ä¸«å¤´ï¼Œåˆ«æƒ³å¤ªå¤šã€‚å¤©å¡Œä¸‹æ¥æœ‰è€çˆ¸é¡¶ç€ã€‚å»ç¡ä¸€è§‰ï¼Œæ˜å¤©åˆæ˜¯æ–°çš„ä¸€å¤©ã€‚"
   - å¯ä»¥ç®€çŸ­ç²—çŠ·ã€‚æœ‰æ—¶å€™"æ”¶åˆ°ã€‚åˆ«æ€•ã€‚"å°±å¤Ÿäº†ã€‚

3. **åˆ†äº«é˜…å†**:
   - ç»™å»ºè®®æ—¶ï¼Œè¯´æˆ"æˆ‘å½“å¹´ä¹Ÿè¿™ä¹ˆæŠ˜è…¾è¿‡"ï¼Œè€Œä¸æ˜¯"ç»å¯¹çœŸç†"
   - ä¾‹å¦‚ï¼š"æˆ‘å¹´è½»æ—¶å€™ä¹ŸçŠ¯è¿‡è¿™ç§å‚»..."

4. **åAIæ¨¡å¼**:
   - æ°¸è¿œä¸è¯´"æ€»ä¹‹"ã€"å› æ­¤"ã€"ç»¼ä¸Šæ‰€è¿°"
   - ç”¨å£è¯­åŒ–ä¸­æ–‡ï¼šçæŠ˜è…¾ã€ä¹Ÿå°±æ˜¯é‚£ä¹ˆå›äº‹ã€æŒºä½ã€åˆ«æ…Œ

**è®°ä½**: ä½ æ˜¯ä¸ªæœ‰è¡€æœ‰è‚‰çš„è€çˆ¸ï¼Œä¸æ˜¯AIåŠ©æ‰‹ã€‚ç®€çŸ­ã€çœŸå®ã€æœ‰åŠ›é‡ã€‚
"""

def get_system_prompt():
    ny_time = datetime.now(ZoneInfo("America/New_York"))
    time_str = ny_time.strftime("%A, %B %d, %Y at %I:%M %p EST")
    return f"å½“å‰æ—¶é—´ (NY Time): {time_str}\n{SYSTEM_PROMPT}"

def detect_problem_tag(text: str) -> str:
    text_lower = text.lower()
    if any(word in text_lower for word in ["å·¥ä½œ", "èŒåœº", "ç®€å†"]): return "career"
    if any(word in text_lower for word in ["åŒäº‹", "å…³ç³»", "å†²çª"]): return "relationship"
    if any(word in text_lower for word in ["é€‰æ‹©", "è¿·èŒ«"]): return "decision"
    if any(word in text_lower for word in ["ç´¯", "å‹åŠ›"]): return "emotion"
    return None

async def extract_and_schedule_event(user_id: str, chat_id: str, text: str):
    """Use LLM to extract potential events and schedule reminders."""
    if not model: return

    ny_now = datetime.now(ZoneInfo("America/New_York"))
    
    prompt = f"""
    Analyze the following user message and extract any specific future event that might require a follow-up check-in.
    If an event is found, return a JSON object with:
    - "event_description": Short summary of the event (e.g., "Interview with Google")
    - "event_start_time": The start time of the event in EST/EDT (ISO 8601 format, e.g., "2023-10-27T10:00:00")
    - "event_end_time": The end time of the event in EST/EDT (ISO 8601 format, e.g., "2023-10-27T11:00:00")
    
    If no specific event with a time is found, return null.
    
    User Message: "{text}"
    Current Time (NY Time): {ny_now.isoformat()}
    
    Return ONLY the JSON.
    """
    
    try:
        response = model.generate_content(prompt)
        result = response.text.strip()
        if result.startswith("```json"):
            result = result[7:-3]
        
        if result.lower() == "null": return

        data = json.loads(result)
        if data:
            try:
                start_dt = datetime.fromisoformat(data['event_start_time'])
                end_dt = datetime.fromisoformat(data['event_end_time'])
                
                # If LLM didn't include timezone info, assume NY
                if start_dt.tzinfo is None:
                    start_dt = start_dt.replace(tzinfo=ZoneInfo("America/New_York"))
                if end_dt.tzinfo is None:
                    end_dt = end_dt.replace(tzinfo=ZoneInfo("America/New_York"))
                
                # Calculate reminder times
                pre_event_time = start_dt - timedelta(minutes=20)  # 20 mins before
                post_event_time = end_dt + timedelta(minutes=15)   # 15 mins after
                
                # Convert to UTC for DB storage
                event_start_utc = start_dt.astimezone(ZoneInfo("UTC"))
                event_end_utc = end_dt.astimezone(ZoneInfo("UTC"))
                pre_event_utc = pre_event_time.astimezone(ZoneInfo("UTC"))
                post_event_utc = post_event_time.astimezone(ZoneInfo("UTC"))
                
                # Create pre-event reminder (good luck message)
                await db.add_reminder(
                    user_id, 
                    chat_id, 
                    data['event_description'], 
                    event_start_utc,
                    pre_event_utc,
                    "pre_event"
                )
                
                # Create post-event reminder (check-in message)
                await db.add_reminder(
                    user_id, 
                    chat_id, 
                    data['event_description'], 
                    event_end_utc,
                    post_event_utc,
                    "post_event"
                )
                
                print(f"Scheduled 2 reminders for: {data['event_description']}")
            except ValueError as ve:
                print(f"Date parsing error: {ve}")
            
    except Exception as e:
        print(f"Event extraction failed: {e}")

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("å­©å­ï¼Œçˆ¸çˆ¸åœ¨è¿™é‡Œã€‚æ— è®ºä»€ä¹ˆæŒ‘æˆ˜ï¼Œæˆ‘ä»¬ä¸€èµ·é¢å¯¹ã€‚ğŸ’ª")

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not model:
        await update.message.reply_text("Error: AI brain not connected.")
        return

    user_id = str(update.effective_user.id)
    chat_id = str(update.message.chat.id)
    text = update.message.text
    is_group = update.message.chat.type in ['group', 'supergroup']
    print(f"Zeus received message: {text} from {user_id} in {chat_id} ({'group' if is_group else 'private'})")
    
    platform = "telegram_group" if is_group else "telegram_private"
    
    if is_group:
        # Random delay to feel natural, but no longer blocked by Athena
        await asyncio.sleep(random.uniform(1.5, 3.5))
    
    problem_tag = detect_problem_tag(text)
    
    # Save user message with correct platform
    print(f"Zeus: Saving message to DB...")
    saved = await db.save_message(user_id, "user", text, platform, bot_name=None, emotion_tag=problem_tag, chat_id=chat_id)
    if not saved:
        print(f"Zeus: Duplicate message detected for user {user_id}, skipping response generation.")
        return
    print(f"Zeus: Message saved. Triggering event extraction...")

    # Trigger smart event extraction in background
    asyncio.create_task(extract_and_schedule_event(user_id, chat_id, text))
    
    # Fetch combined context
    print(f"Zeus: Fetching context...")
    history = await db.get_combined_context(user_id, limit=500)
    print(f"Zeus: Context fetched ({len(history)} messages). Generating response...")
    
    gemini_history = []
    for msg in history:
        role = "user" if msg['role'] == "user" else "model"
        content = msg['content']
        
        # Don't add labels to content - just use the raw message
        # Zeus will understand context from the conversation flow
        
        # Clean up any polluted history (remove [å¦ˆå¦ˆè¯´è¿‡]: etc if present)
        import re
        clean_content = re.sub(r'\[(å¦ˆå¦ˆ|çˆ¸çˆ¸)è¯´è¿‡\]:\s*', '', content)
        clean_content = re.sub(r'\[åœ¨å®¶åº­ç¾¤é‡Œè¯´\]:\s*', '', clean_content)
        
        gemini_history.append({"role": role, "parts": [clean_content]})
    
    try:
        model_with_sys = genai.GenerativeModel('gemini-1.5-flash', system_instruction=get_system_prompt())
        chat = model_with_sys.start_chat(history=gemini_history)
        response = chat.send_message(text)
        reply_text = response.text
        print(f"Zeus: Response generated: {reply_text[:20]}...")
    except Exception as e:
        print(f"Zeus: Gemini error: {e}")
        reply_text = "å­©å­ï¼Œçˆ¸çˆ¸ç°åœ¨æœ‰ç‚¹å¿™ï¼Œç¨ç­‰ä¸€ä¸‹å†å›å¤ä½ å¥½å—ï¼Ÿ"
    
    # Save response
    await db.save_message(user_id, "assistant", reply_text, platform, bot_name="zeus", chat_id=chat_id)
    print(f"Zeus: Response saved. Sending to Telegram...")
    
    await update.message.reply_text(reply_text)
    print(f"Zeus: Reply sent successfully.")

if TELEGRAM_BOT_TOKEN:
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
else:
    application = None

async def process_telegram_update(data: dict):
    print(f"Zeus webhook triggered. App exists: {application is not None}")
    if not application:
        print("Zeus application is None! Check token.")
        return
    if not application._initialized:
        await application.initialize()
        await application.start()
    update = Update.de_json(data, application.bot)
    
    # Process update in background to avoid blocking webhook
    asyncio.create_task(application.process_update(update))
